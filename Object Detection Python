import pyzed.sl as sl
import cv2
import sys
import math
import numpy as np
import socket
import time

zed = sl.Camera()


mi_socket=socket.socket()
# mi_socket.connect(("192.168.1.32",5000))

mi_socket.connect(("172.30.65.132",5000))
message=mi_socket.recv(1024)
print(message.decode())
# Camera Configuration
def initial_Camera():
    init_params = sl.InitParameters()
    init_params.camera_resolution = sl.RESOLUTION.HD2K
    init_params.camera_fps = 15

    # Using Depth Sensing configuration
    init_params.depth_mode = sl.DEPTH_MODE.PERFORMANCE
    init_params.coordinate_units = sl.UNIT.MILLIMETER

    # Open the camera
    err = zed.open(init_params)
    if err != sl.ERROR_CODE.SUCCESS:
        print('Camera is not detected')
        exit(-1)

    print('Camera initialized')
    print('Start Capturing image...')


def object_detection():
    print("Please select object to be detected:\n 1.Brown Cap Bottle\n 2.Coke Bottle")
    num = int(input())
    if num == 1:
        print('Detecting Brown Cap Bottle...')
        template = cv2.imread('/Users/iamvi/PycharmProjects/FinalYearProject/Template_img/1.png', 0)
        w, h = template.shape[::-1]
        return template, w, h
    if num == 2:
        print('Detecting Coke Bottle...')
        template = cv2.imread('/Users/iamvi/PycharmProjects/FinalYearProject/Template_img/CokeBottle.png', 0)
        w, h = template.shape[::-1]
        return template, w, h

    elif num != 1 & num != 2:
        print('Invalid input')
        print('Exit...')


# Detect object and return pixel (x,y)
def grab_Image(flag,coordinatelist):
    if flag == 0:
        img = sl.Mat()
        runtime_parameters = sl.RuntimeParameters()

        if zed.grab(runtime_parameters) == sl.ERROR_CODE.SUCCESS:
            # A new image and depth is available if grab() returns SUCCESS
            zed.retrieve_image(img, sl.VIEW.LEFT)  # Retrieve left image
            # Convert the Retrieve image into Numpy array
            num_img = img.get_data()
            cv2.imshow("Original image", num_img)


    # if flag == 1:
    #     image = sl.Mat()
    #     depth = sl.Mat()
    #     point_cloud = sl.Mat()
    #     runtime_parameters = sl.RuntimeParameters()
    #     if zed.grab(runtime_parameters) == sl.ERROR_CODE.SUCCESS:
    #         # A new image is available if grab() returns sl.ERROR_CODE.SUCCESS
    #         zed.retrieve_image(image, sl.VIEW.LEFT)  # Get the left image
    #         zed.retrieve_measure(depth, sl.MEASURE.DEPTH) # Retrieve depth matrix. Depth is aligned on the left RGB image
    #         zed.retrieve_measure(point_cloud, sl.MEASURE.XYZRGBA) # Retrieve colored point cloud
    #         num_img = image.get_data()
    #         cv2.imshow("Original image", num_img)
    #         for i in range(len(coordinatelist)):
    #             x=coordinatelist[i][0]
    #             y=coordinatelist[i][-1]
    #             depth_value = depth.get_value(x, y)
    #             print("Distance to Camera at ({0}, {1}): {2} mm".format(x, y, depth_value))

    if cv2.waitKey(1) & 0XFF == ord('s'):
        cv2.imwrite('/Users/iamvi/PycharmProjects/FinalYearProject/Template_img/bottles.png', num_img)
        print('Image Saved')

    if cv2.waitKey(10) & 0xFF == ord('q'):
        zed.close()
        cv2.destroyAllWindows()
        flag = 1
        return flag


def template_matching(temp, w, h, previous_x, previous_y, coordlist):
    print('Detecting bottles....')
    point_cloud = sl.Mat()
    bottleimg = cv2.imread('/Users/iamvi/PycharmProjects/FinalYearProject/Template_img/bottles.png')

    # Template Matching
    tempBlur = cv2.medianBlur(temp, 5)
    gray_img = cv2.cvtColor(bottleimg, cv2.COLOR_BGR2GRAY)
    res = cv2.matchTemplate(gray_img, tempBlur, cv2.TM_CCOEFF_NORMED)
    threshold = 0.8
    loc = np.where(res >= threshold)
    for pt in zip(*loc[::-1]):
        cv2.rectangle(bottleimg, pt, (pt[0] + w, pt[1] + h), (0, 0, 255), 2)
        center_x = pt[0] + round(w / 2)
        center_y = pt[1] + round(h / 2)
        cv2.circle(bottleimg, (center_x, center_y), 3, (0, 255, 0), -1)

        # Collect coordinate x,y
        if center_x != previous_x or center_y != previous_y:

            error_x = abs(previous_x - center_x)
            error_y = abs(previous_y - center_y)
            if error_x > 10 and error_y > 10:
                previous_x = center_x
                previous_y = center_y
                print('x coordinate:' + str(center_x), '   y coordinate:' + str(center_y))

                cv2.putText(bottleimg, '{},{}'.format(center_x, center_y), (pt[0], pt[1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 1, cv2.LINE_AA)
                # Measure the distance of a point in the scene represented by pixel (i,j)
                # zed.retrieve_measure(point_cloud, sl.MEASURE.XYZRGBA)
                # Get the 3D point cloud values for pixel (i,j)
                # point3D = point_cloud.get_value(center_x, center_y)
                # point3D_value=point3D[1]
                # x = point3D_value[0]
                # y = point3D_value[1]
                # z = point3D_value[2]
                # color = point3D_value[3]
                # z_distance = math.sqrt(x*x + y*y + z*z)
                coordlist.append([center_x, center_y])
                # print('z coordinate:' +str(z_distance)+'mm')

    if len(coordlist) > 0:
        cv2.imwrite('/Users/iamvi/PycharmProjects/FinalYearProject/Template_img/bottles_test.png', bottleimg)
        print('Bottle Detected image saved')

    return coordlist




def main(args):
    looping = True
    flag = 0
    bottle_coordinate_list = []
    x_origin, y_origin = 0, 0
    initial_Camera()
    while looping:
        # Grab an image when robot is in position
        flag=0
        flag = grab_Image(flag,bottle_coordinate_list)
        if flag == 1:
            looping = False

    temp, w, h = object_detection()
    bottle_coordinate_list = template_matching(temp, w, h, x_origin, y_origin, bottle_coordinate_list)
    print(bottle_coordinate_list)

    # initial_Camera()
    # while flag==1:
    #     grab_Image(flag,bottle_coordinate_list)


    # num_objects=str(len(bottle_coordinate_list))
    # mi_socket.send(num_objects.encode())
    #Ask the robot to send the feedback from Robotsudio when one bottle is placed in the box
    for i in range(len(bottle_coordinate_list)):
        for a in range(len(bottle_coordinate_list[i])):

            print(str(bottle_coordinate_list[i][a]))
            string=str(bottle_coordinate_list[i][a])
            mi_socket.send(string.encode())
            time.sleep(1.5)
        print('Ready to grab next object? (Y/N)')
        #message=mi_socket.recv(1024)
        if message.decode()=='Y':
            continue
    print('Program ended')


if __name__ == '__main__':
    main(sys.argv)
   
